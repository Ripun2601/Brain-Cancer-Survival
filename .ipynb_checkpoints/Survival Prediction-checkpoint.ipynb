{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1782b4",
   "metadata": {},
   "source": [
    "## setup env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abd55e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/miykael/gif_your_nifti\n",
      "  Cloning https://github.com/miykael/gif_your_nifti to c:\\users\\bisha\\appdata\\local\\temp\\pip-req-build-i05blufl\n",
      "  Resolved https://github.com/miykael/gif_your_nifti to commit 6e7818502bfd998ba437a0a6688d7cc1efbaef5e\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gif-your-nifti==0.2.0) (1.23.5)\n",
      "Requirement already satisfied: nibabel in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gif-your-nifti==0.2.0) (5.1.0)\n",
      "Requirement already satisfied: imageio<2.28 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gif-your-nifti==0.2.0) (2.27.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gif-your-nifti==0.2.0) (3.7.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imageio<2.28->gif-your-nifti==0.2.0) (9.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->gif-your-nifti==0.2.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bisha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->gif-your-nifti==0.2.0) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/miykael/gif_your_nifti 'C:\\Users\\bisha\\AppData\\Local\\Temp\\pip-req-build-i05blufl'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# neural imaging\n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "!pip install git+https://github.com/miykael/gif_your_nifti \n",
    "import gif_your_nifti.core as gif2nif\n",
    "# ml libs\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873fdf6",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d4e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE seg-areas  \n",
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', \n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
    "}\n",
    "\n",
    "# days start interval\n",
    "SURVIVAL_CATEGORIES= {\n",
    "    'SHORT' : 0 , # 0-300\n",
    "    'MEDIUM' : 300,  # 300-450\n",
    "    'LONG' : 450, # 450 and more\n",
    "}\n",
    "\n",
    "# there are 155 slices per volume\n",
    "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
    "VOLUME_SLICES = 100 \n",
    "VOLUME_START_AT = 22 # first slice of volume that we will include\n",
    "IMG_SIZE=128\n",
    "TRAIN_DATASET_PATH='C:/Users/bisha/Desktop/archive (2)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bb25c",
   "metadata": {},
   "source": [
    "## Split Dataset into train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b897d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
    "train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n",
    "\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c84a6c",
   "metadata": {},
   "source": [
    "## Check if the background of images contains only zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loc_slice=73\n",
    "image_volume=nib.load(TRAIN_DATASET_PATH+'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "my_img=image_volume[:,:,my_loc_slice]\n",
    "my_converted_img = my_img.copy()\n",
    "my_converted_img[my_converted_img == 0] = 666\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(1,2, figsize = (10, 5))\n",
    "axarr[0].imshow(my_img)\n",
    "axarr[1].imshow(my_converted_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7717e3f",
   "metadata": {},
   "source": [
    "##### Count number of pixels for each segment for each slice in volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb10218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskSizeForSlice(path,i_slice):\n",
    "    totals = dict([(1, 0), (2, 0), (3, 0)])\n",
    "    image_volume=nib.load(path).get_fdata()\n",
    "    # flatten 3D image into 1D array and convert mask 4 to 2\n",
    "    arr=image_volume[:,:,i_slice].flatten()\n",
    "    arr[arr == 4] = 3\n",
    "\n",
    "    unique, counts = np.unique(arr, return_counts=True)\n",
    "    unique = unique.astype(int)\n",
    "    values_dict=dict(zip(unique, counts))\n",
    "    for k in range(1,4):\n",
    "        totals[k] += values_dict.get(k,0)\n",
    "    return totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60264d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loc_slice=73\n",
    "my_loc_class=1\n",
    "seg_sum=maskSizeForSlice(TRAIN_DATASET_PATH+'BraTS20_Training_001/BraTS20_Training_001_seg.nii',my_loc_slice)\n",
    "\n",
    "\n",
    "image_volume=nib.load(TRAIN_DATASET_PATH+'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n",
    "image_loc=image_volume[:,:,my_loc_slice]\n",
    "image_loc[image_loc != my_loc_class] = 0\n",
    "\n",
    "# plot segment only for class 'my_loc_class'\n",
    "plt.imshow(image_loc)\n",
    "\n",
    "image_loc=image_loc.flatten()\n",
    "count = np.count_nonzero(image_loc == my_loc_class)\n",
    "print(f'count class {my_loc_class}: {count}')\n",
    "print(seg_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff3140",
   "metadata": {},
   "source": [
    "# Survival prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8455e",
   "metadata": {},
   "source": [
    "##### Lets see what is the age distrubution in our dataset and their survival days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d260c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_path = \"C:/Users/bisha/Desktop/archive (2)/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/survival_info.csv\"\n",
    "age_dict = {}\n",
    "days_dict = {}\n",
    "\n",
    "\n",
    "with open(csv_path, mode='r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file,delimiter = ',')\n",
    "  #  row_count = sum(1 for row in csv_reader)\n",
    " #   print(f'total rows: {row_count} .')\n",
    "    at_line = 0\n",
    "    category_short = 0\n",
    "    category_medium = 0\n",
    "    category_long = 0\n",
    "    max_days = 0\n",
    "    for row in csv_reader:\n",
    "        if at_line == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            at_line += 1\n",
    "        else:\n",
    "            if (row[3] != \"GTR\"):\n",
    "                continue\n",
    "            print(row)\n",
    "            key = row[0]\n",
    "            age = row[1]\n",
    "            days = row[2]\n",
    "            if (not days.isnumeric()):\n",
    "                continue\n",
    "            age_dict[key] = float(age)\n",
    "            days_dict[key] = int(days)\n",
    "            max_days = max(max_days,int(days))\n",
    "            if int(days) < 250:\n",
    "                category_short += 1\n",
    "            elif (int(days) >= 250 and int(days) <= 450):\n",
    "                category_medium += 1\n",
    "            else:\n",
    "                category_long += 1\n",
    "            at_line+=1\n",
    "\n",
    "    print(f'Processed {at_line} lines.')\n",
    "    print(category_short,category_medium,category_long)\n",
    "    print(max_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import cycle\n",
    "#age_dict, days_dict \n",
    "\n",
    "# round values in dictionary\n",
    "age_dict_rounded = {key : round(age_dict[key], 0) for key in age_dict}\n",
    "# survival days are very distinct values => move the values in ranges per 20\n",
    "days_dict_rounded = {key : round(days_dict[key]/20)*20 for key in days_dict}\n",
    "\n",
    "# count same numbers => create statistics how many times is there person with same age\n",
    "age_dict_rounded_counted = Counter(age_dict_rounded.values())\n",
    "days_dict_rounded_counted = Counter(days_dict_rounded.values())\n",
    "\n",
    "cycol = cycle('bgrcmk')\n",
    "colors = list()\n",
    "for i in range(len(age_dict_rounded_counted)):\n",
    "    colors.append(next(cycol))\n",
    "    \n",
    "cycol = cycle('bgrcmk')    \n",
    "colorsDays = list()\n",
    "for i in range(len(days_dict_rounded_counted)):\n",
    "    colorsDays.append(next(cycol))\n",
    "\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.xlabel('Number of people with (rounded) age')\n",
    "plt.ylabel('Age (rounded)')\n",
    "plt.title(\"(Rounded) age distrubution in dataset\")\n",
    "plt.bar(list(age_dict_rounded_counted.keys()), age_dict_rounded_counted.values(), color=colors)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6), dpi=80)\n",
    "plt.xlabel('Days survived')\n",
    "plt.ylabel('Number of people (rounded to 20)')\n",
    "plt.title(\"Survival days distribution\")\n",
    "plt.bar(list(days_dict_rounded_counted.keys()), days_dict_rounded_counted.values(),width=15, color=colorsDays)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32394d1b",
   "metadata": {},
   "source": [
    "### Computing segment sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e18e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of pixels for each segment as dictionary\n",
    "# original images contain segment values (0,1,2,4) => 4 is our 3 ... :)\n",
    "def getMaskSizesForVolume(image_volume):\n",
    "    totals = dict([(1, 0), (2, 0), (3, 0)])\n",
    "    for i in range(VOLUME_SLICES):\n",
    "        # flatten 2D image into 1D array and convert mask 4 to 2\n",
    "        arr=image_volume[:,:,i+VOLUME_START_AT].flatten()\n",
    "        arr[arr == 4] = 3\n",
    "        \n",
    "        unique, counts = np.unique(arr, return_counts=True)\n",
    "        unique = unique.astype(int)\n",
    "        values_dict=dict(zip(unique, counts))\n",
    "        for k in range(1,4):\n",
    "            totals[k] += values_dict.get(k,0)\n",
    "    return totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e32c7e",
   "metadata": {},
   "source": [
    "##### Compute brain volume size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns count of non zero elements in whole 3D volume\n",
    "def getBrainSizeForVolume(image_volume):\n",
    "    total = 0\n",
    "    for i in range(VOLUME_SLICES):\n",
    "        arr=image_volume[:,:,i+VOLUME_START_AT].flatten()\n",
    "        image_count=np.count_nonzero(arr)\n",
    "        total=total+image_count\n",
    "    return total\n",
    "\n",
    "example_volume=nib.load(TRAIN_DATASET_PATH+'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "\n",
    "f, axarr = plt.subplots(1,2, figsize = (8, 4))\n",
    "axarr[0].imshow(example_volume[:,:,VOLUME_START_AT])\n",
    "axarr[1].imshow(example_volume[:,:,VOLUME_START_AT+30])\n",
    "\n",
    "print(f'total count: {getBrainSizeForVolume(example_volume)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4383e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create only age: category data\n",
    "\n",
    "# id: age, categories\n",
    "def getListAgeDays(id_list):\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    for i in id_list:\n",
    "        if (i not in age_dict):\n",
    "            continue\n",
    "        masks = getMaskSizesForVolume(nib.load(TRAIN_DATASET_PATH + f'BraTS20_Training_{i[-3:]}/BraTS20_Training_{i[-3:]}_seg.nii').get_fdata())\n",
    "        brain_vol = getBrainSizeForVolume(nib.load(TRAIN_DATASET_PATH + f'BraTS20_Training_{i[-3:]}/BraTS20_Training_{i[-3:]}_t1.nii').get_fdata())\n",
    "        masks[1] = masks[1]/brain_vol\n",
    "        masks[2] = masks[2]/brain_vol\n",
    "        masks[3] = masks[3]/brain_vol\n",
    "        merged=[age_dict[i],masks[1],masks[2],masks[3]] ## add segments\n",
    "        x_val.append(merged) \n",
    "        if (days_dict[i] < 250):\n",
    "            y_val.append([1,0,0])\n",
    "        elif (days_dict[i] >= 250 and days_dict[i] < 450):\n",
    "            y_val.append([0,1,0])\n",
    "        else:\n",
    "            y_val.append([0,0,1])\n",
    "            \n",
    "    return np.array(x_val), np.array(y_val)\n",
    "\n",
    "X_all, y_all = getListAgeDays(train_and_test_ids)\n",
    "\n",
    "print(f'X_test: {X_all.shape}')\n",
    "df = pd.DataFrame(np.concatenate((X_all, y_all), axis=1) , columns = [\"age\",f\"{SEGMENT_CLASSES[1]}\",f\"{SEGMENT_CLASSES[2]}\",f\"{SEGMENT_CLASSES[3]}\",\"short\",\"medium\",\"long\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b174e04",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "v = X_all\n",
    "v_scaled = scaler.fit_transform(v)\n",
    "X_all = v_scaled\n",
    "\n",
    "df = pd.DataFrame(X_all, columns = [\"age normalised\",f\"{SEGMENT_CLASSES[1]}\",f\"{SEGMENT_CLASSES[2]}\",f\"{SEGMENT_CLASSES[3]}\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066f49d",
   "metadata": {},
   "source": [
    "##### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "df = pd.DataFrame(X_all, columns = [\"age\", SEGMENT_CLASSES[1],SEGMENT_CLASSES[2],SEGMENT_CLASSES[3]])\n",
    "sns.pairplot(df, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all,test_size = 0.2, random_state = 42, shuffle = True)\n",
    "\n",
    "\n",
    "print(\"x_train shape:\",X_train.shape)\n",
    "print(\"x_test shape:\", X_train.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17649b5e",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34152d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=3, random_state=0)\n",
    "\n",
    "# fit the model to the training set\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Model accuracy score with 3 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(rfc, X_train, y_train, cv=3)\n",
    "# rfc.fit(X_train,y_train)\n",
    "\n",
    "print(\"Cross validation: Train Score:\",np.mean(accuracies))\n",
    "print(\"Cross validation: Test Score:\",rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88943b5",
   "metadata": {},
   "source": [
    "###### Visualize the most important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673eb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train, columns = [\"age\",f\"{SEGMENT_CLASSES[1]}\",f\"{SEGMENT_CLASSES[2]}\",f\"{SEGMENT_CLASSES[3]}\"])\n",
    "\n",
    "feature_scores = pd.Series(rfc.feature_importances_, index=df.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d987e",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44da0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d3602",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229002bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'n_estimators':np.arange(1,100,1),\n",
    "    'criterion':['gini','entropy']\n",
    "    }\n",
    "\n",
    "rfc_ = RandomForestClassifier(random_state = 42)\n",
    "rf_grid = GridSearchCV(rfc_, grid, cv=5)\n",
    "rf_grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"Hyperparameters:\",rf_grid.best_params_)\n",
    "print(\"Train Score:\", rf_grid.best_score_)\n",
    "print(\"Test Score:\",rf_grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260caea",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#convert one hot into multilabel\n",
    "y_train_multi=np.argmax(y_train, axis=1)\n",
    "y_test_multi =np.argmax(y_test, axis=1)\n",
    "\n",
    "svc = SVC(random_state = 42, C=10, degree=3, gamma=1, kernel='poly')\n",
    "svc.fit(X_train,y_train_multi)\n",
    "accuracies = cross_val_score(svc, X_train, y_train_multi)\n",
    "\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test_multi, y_pred)))\n",
    "\n",
    "\n",
    "print(\"Cross validation: Train Score:\",np.mean(accuracies))\n",
    "print(\"Cross validation: Test Score:\",svc.score(X_test,y_test_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one hot\n",
    "y_pred=y_pred.astype(int)\n",
    "n_values = np.max(y_pred) + 1\n",
    "y_pred_hot=np.eye(n_values)[y_pred]\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred_hot.argmax(axis=1))\n",
    "\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_multi, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8a77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'C':[0.01,0.1,1,10,15,20],\n",
    "    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "    'degree' : [1,3,5,7],\n",
    "    'gamma' : [0.01,1]\n",
    "}\n",
    "\n",
    "svm  = SVC();\n",
    "svm_grid = GridSearchCV(svm, grid, cv = 5)\n",
    "svm_grid.fit(X_train,y_train_multi)\n",
    "print(\"Best Parameters:\",svm_grid.best_params_)\n",
    "print(\"Train Score:\",svm_grid.best_score_)\n",
    "print(\"Test Score:\",svm_grid.score(X_test,y_test_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b0e3e",
   "metadata": {},
   "source": [
    "## KNN Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f129f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn  = KNeighborsClassifier(n_neighbors=38, p=2, weights='distance')\n",
    "knn.fit(X_train,y_train_multi)\n",
    "accuracies = cross_val_score(knn, X_train, y_train_multi)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test_multi, y_pred)))\n",
    "\n",
    "\n",
    "print(\"Cross validation: Train Score:\",np.mean(accuracies))\n",
    "print(\"Cross validation: Test Score:\",knn.score(X_test,y_test_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one hot\n",
    "y_pred=y_pred.astype(int)\n",
    "n_values = np.max(y_pred) + 1\n",
    "y_pred_hot=np.eye(n_values)[y_pred]\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred_hot.argmax(axis=1))\n",
    "\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_multi, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'n_neighbors':np.arange(1,75),\n",
    "    'p':np.arange(1,5),\n",
    "    'weights':['uniform','distance']\n",
    "    }\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn,grid,cv=5)\n",
    "knn_grid.fit(X_train,y_train_multi)\n",
    "\n",
    "print(\"Hyperparameters:\",knn_grid.best_params_)\n",
    "print(\"Train Score:\",knn_grid.best_score_)\n",
    "print(\"Test Score:\",knn_grid.score(X_test,y_test_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36454087",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=11,\n",
    "    max_iter=150,\n",
    "    alpha=1e-05,\n",
    "    solver='lbfgs',\n",
    "    verbose=10,\n",
    "    random_state=6,\n",
    "    tol=0.000000001\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train_multi)\n",
    "accuracies = cross_val_score(clf, X_train, y_train_multi)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test_multi, y_pred)))\n",
    "\n",
    "\n",
    "print(\"Cross validation: Train Score:\",np.mean(accuracies))\n",
    "print(\"Cross validation: Test Score:\",knn.score(X_test,y_test_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one hot\n",
    "y_pred=y_pred.astype(int)\n",
    "n_values = np.max(y_pred) + 1\n",
    "y_pred_hot=np.eye(n_values)[y_pred]\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred_hot.argmax(axis=1))\n",
    "\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [25,50,100,150,200,300,500,1000 ],\n",
    "    'alpha': 10.0 ** -np.arange(1, 10),\n",
    "    'hidden_layer_sizes':np.arange(10, 15),\n",
    "    'random_state':[0,1,2,3,4,5,6,7,8,9]\n",
    "}\n",
    "clf_grid = GridSearchCV(MLPClassifier(), grid, n_jobs=-1)\n",
    "\n",
    "clf_grid.fit(X_train, y_train_multi)\n",
    "\n",
    "print(\"Hyperparameters:\",clf_grid.best_params_)\n",
    "print(\"Train Score:\",clf_grid.best_score_)\n",
    "print(\"Test Score:\",clf_grid.score(X_test, y_test_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154b04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
